{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Classification_Predict_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drikus-d/unsupervised-predict-streamlit-template/blob/main/Macs_Unsupervised_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBPJ9hI1oPa3"
      },
      "source": [
        "#**<font color='red'> Movie Recommender Systems: Unsupervised Learning - EDSA</font>**\n",
        "\n",
        "Â© Explore Data Science Academy\n",
        "\n",
        "Team 5\n",
        "##**<font color='green'> Movie Recommender System</font>**\n",
        "\n",
        "<p align=\"justify\" > \n",
        "\n",
        "This Unsupervised predict layout is as follows:\n",
        "\n",
        "1. Introduction\n",
        "2. Importing libraries and loading data\n",
        "3. Exploratory Data Analysis\n",
        "4. Data pre-processing\n",
        "5. Building models\n",
        "7. Conclusion\n",
        "8. Submission\n",
        "\n",
        "\n",
        "##**<font color='cyan'>Problem Statement:</font>**\n",
        "Develop an unsupervised machine learning model that can accurately predict how a user would rate a movie they haven't seen based on their previous browsing history and/or content or collaborative filtering.\n",
        "\n",
        "##**<font color='purple'>Task: Movie Recommender System</font>**\n",
        "<p align=\"justify\" > To construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
        "\n",
        "<div align=\"center\" style=\"width: 800px; font-size: 100%; text-align: center; margin: 0 auto\">\n",
        "<img src=\"https://raw.githubusercontent.com//master/Screenshot%20(480).png\"\n",
        "\n",
        "Recommender System Photo by <a href=\"https://explore-datascience.net\"> explore-datascience.net </a> \n",
        "</div>\n"
      ],
      "id": "uBPJ9hI1oPa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNg4G34So5B6"
      },
      "source": [
        "# Importing libraries\n",
        "\n",
        "In this section we are importing all the relavant packages which will be used for analysis and modeling."
      ],
      "id": "xNg4G34So5B6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl7BaXRYpDN6"
      },
      "source": [
        "# Libraries for data loading, data manipulation and data visulisation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Libraries for data preparation and model building\n",
        "# Import the scaling module\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "# Import train/test split module\n",
        "\n",
        "#Modelling \n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# NLP Libraries\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer,SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "id": "Gl7BaXRYpDN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-whIlITEpsXI"
      },
      "source": [
        "#Loading DataSets\n",
        "\n",
        " Loading the data to be used to build our classification model."
      ],
      "id": "-whIlITEpsXI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-28T08:49:35.311495Z",
          "start_time": "2021-06-28T08:49:35.295494Z"
        },
        "id": "fbbb6c18"
      },
      "source": [
        "# Loading in the datasets\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "movies = pd.read_csv('movies.csv')\n",
        "imdb_data = pd.read_csv('imdb_data.csv')\n",
        "tags = pd.read_csv('tags.csv')\n",
        "links_df = pd.read_csv('./links.csv')\n",
        "\n",
        "genome_score = pd.read_csv('.genome_scores.csv')\n",
        "genome_tags = pd.read_csv('.genome_tags.csv')"
      ],
      "id": "fbbb6c18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Description:**\n",
        "\n",
        "<p align=\"justify\" > \n",
        "genome_scores.csv - a score mapping the strength between movies and tag-related properties. \n",
        "\n",
        "genome_tags.csv - user assigned tags for genome-related scores\n",
        "\n",
        "imdb_data.csv - Additional movie metadata scraped from IMDB using the links.csv file.\n",
        "\n",
        "links.csv - File providing a mapping between a MovieLens ID and associated IMDB and TMDB IDs.\n",
        "\n",
        "sample_submission.csv - Sample of the submission format for the hackathon.\n",
        "\n",
        "tags.csv - User assigned for the movies within the dataset.\n",
        "\n",
        "test.csv - The test split of the dataset. Contains user and movie IDs with no rating data.\n",
        "\n",
        "train.csv - The training split of the dataset. Contains user and movie IDs with associated rating data."
      ],
      "metadata": {
        "id": "TzmTE2txABLD"
      },
      "id": "TzmTE2txABLD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w7--NjyPE8"
      },
      "source": [
        "<a id=\"three\"></a>\n",
        "# Exploratory Data Analysis\n",
        "\n",
        "\n",
        "<p align=\"justify\" > This section provides an in depth EDA which allows us to gain deeper insights into the dimensions and features of our data.\n",
        "\n",
        "We will take a closer look at our data to check for obvious and hidden underlying clues and relationships that exist within our differrent classes. "
      ],
      "id": "O2w7--NjyPE8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwOi1mBtxkHe"
      },
      "source": [
        "#Checking the shape of the train and test set\n",
        "train.shape,test.shape"
      ],
      "id": "fwOi1mBtxkHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48pfhgkCqokV"
      },
      "source": [
        "round((train.isnull().sum()/test.shape[0])\n",
        "      *100,2).astype(str)+ ' %'\n"
      ],
      "id": "48pfhgkCqokV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GpulHyrquJB"
      },
      "source": [
        "\n",
        "Missing Data:"
      ],
      "id": "8GpulHyrquJB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu4SY0zOqbg3"
      },
      "source": [
        "train.info()"
      ],
      "id": "Gu4SY0zOqbg3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies.info()"
      ],
      "metadata": {
        "id": "8UiHualOBnCB"
      },
      "id": "8UiHualOBnCB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW6zw_Rg1mbK"
      },
      "source": [
        "### Data cleaning"
      ],
      "id": "fW6zw_Rg1mbK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GKnoPiL1mmq"
      },
      "source": [
        "\n",
        "\n",
        "<p align=\"justify\" >  Data cleaning is the process of detecting and correcting corrupt or inaccurate records from the dataset and identifying incomplete, incorrect, inaccurate, or irrelevant parts of the data."
      ],
      "id": "5GKnoPiL1mmq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metric"
      ],
      "metadata": {
        "id": "IF41zf2BoSI1"
      },
      "id": "IF41zf2BoSI1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics used to gauge model performance is the Root Mean Square Error. Root Mean Square Error (RMSE) is commonly used in regression analysis and forecasting, and measures the standard deviation of the residuals arising between predicted and actual observed values for a modelling process. For our task of generating user movie ratings via recommendation algorithms, the the formula is given by:\n",
        "\n",
        "RMSE.PNG\n",
        "\n",
        "Where R is the total number of recommendations generated for users and movies, with r{ui} and r-hat{ui} being the true, and predicted ratings for user u watching movie i, respectively."
      ],
      "metadata": {
        "id": "nOoDg6NWlVHG"
      },
      "id": "nOoDg6NWlVHG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QR2mnfgF-nJ"
      },
      "source": [
        "### Submission"
      ],
      "id": "8QR2mnfgF-nJ"
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.DataFrame({\"\":df_test[''], '': pred})\n",
        "sub = sub.set_index('')\n",
        "sub.to_csv('submission.csv',index=True)\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "lva0kPL-dvWq"
      },
      "id": "lva0kPL-dvWq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To Comet:"
      ],
      "metadata": {
        "id": "OwUBuODZcwHY"
      },
      "id": "OwUBuODZcwHY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**<font color='green'>Conclusion: </font>**\n",
        "\n",
        "<p align=\"justify\" > \n",
        "\n",
        "##**<font color='green'>Recommendations: </font>**\n",
        "\n",
        "<p align=\"justify\" > "
      ],
      "metadata": {
        "id": "VOlmkxI2d0Xq"
      },
      "id": "VOlmkxI2d0Xq"
    }
  ]
}